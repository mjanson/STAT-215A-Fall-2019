\batchmode
\makeatletter
\makeatother
\documentclass[english]{article}\usepackage[]{graphicx}\usepackage[]{color}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{geometry}
\geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
\usepackage{fancyhdr}
\pagestyle{fancy}
\setlength{\parskip}{\smallskipamount}
\setlength{\parindent}{0pt}
\usepackage{url}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage[authoryear]{natbib}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
\providecommand{\LyX}{L\kern-.1667em\lower.25em\hbox{Y}\kern-.125emX\@}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
\numberwithin{equation}{section}
\numberwithin{figure}{section}

\@ifundefined{date}{}{\date{}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
\pagestyle{empty} 

\makeatother

\usepackage{babel}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}

\title{Lab 2 - Stat 215A, Fall 2019\vskip -3em}
\maketitle
\begin{center}
\textbf{Due: Thursday October 10, 11:59 PM}\pagestyle{empty}
\par\end{center}

Push a folder called ``lab2'' to your stat-215-a GitHub repository. This folder, ``lab2'', should contain the files below:

\begin{itemize}
\item \textbf{lab2.Rmd} or lab2.Rnw: the raw report + code with your name 
\item \textbf{lab2.pdf}: the output of lab2.Rnw/lab2.Rmd. This output should not contain any code.
\item \textbf{lab2\_blind.Rmd} or lab2\_blind.Rnw: exactly the same as lab2.Rmd/lab2.Rnw but with your student ID instead of your name
\item \textbf{lab2\_blind.pdf}: the output of lab2\_blind.Rnw/lab2\_blind.Rmd. This output should not contain any code.
\item \textbf{R/}: a folder containing .R scripts (e.g. load.R and clean.R) that will be sourced in lab2.Rmd
\item \textbf{other/}: an optional folder containing other miscellaneous files required to reproduce your lab2.Rmd.
\end{itemize}

You should also have a local \textbf{data/} (and an optional \textbf{documents/}) folder but please do not push these folders. Do not push any other files that are not needed for your report, and do not push multiple versions of the lab. Please make an effort to adhere to these filenames exactly, otherwise there is a chance that your lab will not be properly transferred for peer grading.

\section{Linguistic Data}

This section of the lab uses data from a Dialect Survey conducted by Bert Vaux. Some limited information can be found at the original website \url{http://www4.uwm.edu/FLL/linguistics/dialect/index.html}. The questions and answers can be found in the file \texttt{question\_data.Rdata} (this information was found and processed from the \url{http://dialect.redlog.net/index.html}
by an intrepid STAT215A student past). We will focus on the questions that look at lexical differences as opposed to phonetic differences, which are numbered 50-121. There two data sets on GitHub and bCourses. \texttt{lingData} contains the answers to the questions for 47,471 respondents across the United States. The dataset contains the variables \texttt{ID},
\texttt{CITY}, \texttt{STATE}, \texttt{ZIP}, \texttt{Q50} - \texttt{Q121} (a few questions in this range are left out), \texttt{lat} and \texttt{long}.
\texttt{ID} is a number identifying the respondent. \texttt{CITY} and \texttt{STATE} were self reported by respondents. Former GSIs found the latitude and longitude for the center of each zipcode and
added the \texttt{lat} and \texttt{long} variables based on the reported city and state. Note that there are missing values. The variables starting with \texttt{Q} are the responses to the corresponding question
on the website. A value of 0 indicates no response. The other numbers should directly match the responses on the website, i.e. a value of 1 should match a response of (a).

For the second data set, \texttt{lingLocation}, the same categorical responses were turned into binary responses. Then the data was binned into one degree latitude by one degree longitude squares. Within each of these bins, the binary response vectors were summed over individuals.
Please note that the rows are not normalized.

For example, say John and Paul take this questionnaire for two questions. The first question has three answer choices and the second question has four answer choices. If John answered A and D and Paul answered
B and D, then \texttt{lingData} would encode two vectors: $(1,4)$ and $(2,4)$. If they lived in the same longitude and latitude box, then it would
be encoded in \texttt{lingLocation} as one vector: $(1,1,0,0,0,0,2)$.

\subsection{Your tasks}
\begin{enumerate}
\item Have a look at the review papers \citet{nerbonne2003introducing}
and \citet{nerbonne2006progress} (both are posted on GitHub and bCourses). These will provide some information regarding the domain context.
\item As you begin exploring the data, pick two survey questions and investigate their relationship to each other and geography. You will need to use maps to examine the geographical relationships and may want to experiment with interactivity, e.g. using linked brushing (see the \texttt{crosstalk} R package \url{https://rstudio.github.io/crosstalk/} or see an example using \texttt{shiny} \url{https://jjallaire.shinyapps.io/shiny-ggplot2-brushing/}). Do the answers to the two questions define any distinct geographical groups? Does a response to one question help predict the other? Try to analyze the categorical data for more than 2 questions.
\item Encode the data so that the response is binary instead of categorical. In the previous example of John and Paul, the encoded binary vectors would be $(1,0,0,0,0,0,1)$ for John and $(0,1,0,0,0,0,1)$ for Paul. (You might want to do this for the previous question as well.) This makes $p=468$ and $n=47,471$. Experiment with dimension reduction techniques. What do you see? If you do not see anything, change your projection. Does that make things look different? Did you center and/or scale your data before performing dimension reduction? Discuss your choice of centering/scaling. Why is it not a good idea to perform PCA or other dimension reduction techniques on the original \texttt{lingData} dataset?
\item Use the methods we learned in class for clustering to try to gain insights into the full dataset. Perform at least two different clustering methods. Are there any groups/clusters of people? Do these groups relate to geography? Are the clusters completely disparate or is there a continuum? From where to where? Which questions produce this continuum or separate the clusters? How did you choose the number of clusters? Does the mathematical model behind your dimension reduction strategy make sense for these clusters? What are the advantages and disadvantages of the clustering methods that you decided to use?
\item Choose one of your interesting clustering results. Analyze and discuss the robustness of the clusters. What happens when you perturb the data set (e.g., via bootstrap or subsampling)? What happens when you use different starting points in the algorithm? What do you conclude from your clustering and stability analysis?
\end{enumerate}
\bibliographystyle{plainnat}
\bibliography{bib}

\end{document}
